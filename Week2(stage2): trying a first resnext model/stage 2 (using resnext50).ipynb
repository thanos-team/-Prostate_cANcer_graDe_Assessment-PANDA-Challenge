{"cells":[{"metadata":{},"cell_type":"markdown","source":"Before reading:\n\nhttps://github.com/Nhan121/Kaggle-6-first-projects/blob/master/Prostate%20cANcer%20graDe%20Assessment%20(PANDA)%20Challenge/Draft-version.ipynb\n\nhttps://github.com/thanos-team/-Prostate_cANcer_graDe_Assessment-PANDA-Challenge/blob/master/Week1/Step%201.%20Viewing%20image%2C%20mask_image%20%26%20understanding%20EDA.ipynb"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"## for loading, processing data & using for linear_algebra calculation\nimport numpy as np \nimport pandas as pd \nimport os\n\n# Any results you write to the current directory are saved as output.\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision import transforms,models\nfrom tqdm import tqdm_notebook as tqdm\nimport math\nimport torch.utils.model_zoo as model_zoo\n\n## for processing_image\nimport cv2\nimport openslide\nimport skimage.io\nimport random\nfrom sklearn.metrics import cohen_kappa_score\nimport albumentations\n\n# General packages\nfrom PIL import Image\n\n## print out the names of the first 5 image_files (total = 10 images for train_imgaes & train_label_masks) with the train, test, submission.csv files\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames[:5]:\n        print(os.path.join(dirname, filename))","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/panda-resnext/resnext50_2.pth\n/kaggle/input/panda-resnext/resnext50_1.pth\n/kaggle/input/prostate-cancer-grade-assessment/train.csv\n/kaggle/input/prostate-cancer-grade-assessment/test.csv\n/kaggle/input/prostate-cancer-grade-assessment/sample_submission.csv\n/kaggle/input/prostate-cancer-grade-assessment/train_label_masks/4b223c776c0ddb0699d74f3334c1e5e6_mask.tiff\n/kaggle/input/prostate-cancer-grade-assessment/train_label_masks/b481b56617ce096435cb591adc6dd0b9_mask.tiff\n/kaggle/input/prostate-cancer-grade-assessment/train_label_masks/53dfff0cecd06c15f600d334e7324b78_mask.tiff\n/kaggle/input/prostate-cancer-grade-assessment/train_label_masks/eb846d2f14749c4913bf0affa0578d8d_mask.tiff\n/kaggle/input/prostate-cancer-grade-assessment/train_label_masks/f526a2ca5612d5913984a67edabaf991_mask.tiff\n/kaggle/input/prostate-cancer-grade-assessment/train_images/0cc35bc0fe4dd912b20f72d66888fd49.tiff\n/kaggle/input/prostate-cancer-grade-assessment/train_images/4f53892473ee239f9dc9d80047cb3627.tiff\n/kaggle/input/prostate-cancer-grade-assessment/train_images/9335fbc722c3feb51e73c142238a0751.tiff\n/kaggle/input/prostate-cancer-grade-assessment/train_images/573ad8015383dce02cbe6dd1b9b0819c.tiff\n/kaggle/input/prostate-cancer-grade-assessment/train_images/ceaed3c478ce8e0366c1e3d30edf1192.tiff\n/kaggle/input/torch-se-resnext/se_resnext50_32x4d-a260b3a4.pth\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Loading & viewing dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Location of the training images\nBASE_PATH = '../input/prostate-cancer-grade-assessment'\nprint(os.listdir(BASE_PATH))\n\n# image and mask directories\ndata_dir = f'{BASE_PATH}/train_images'\nmask_dir = f'{BASE_PATH}/train_label_masks'\n\n\n# Location of training labels\ntrain = pd.read_csv(f'{BASE_PATH}/train.csv')\ntest = pd.read_csv(f'{BASE_PATH}/test.csv')\nsubmission = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')","execution_count":2,"outputs":[{"output_type":"stream","text":"['train_label_masks', 'train.csv', 'train_images', 'test.csv', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(7)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                           image_id data_provider  isup_grade gleason_score\n0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0\n1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0\n2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4\n3  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4\n4  001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0\n5  002a4db09dad406c85505a00fb6f6144    karolinska           0           0+0\n6  003046e27c8ead3e3db155780dc5498e    karolinska           1           3+3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>data_provider</th>\n      <th>isup_grade</th>\n      <th>gleason_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0005f7aaab2800f6170c399693a96917</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n      <td>radboud</td>\n      <td>4</td>\n      <td>4+4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n      <td>karolinska</td>\n      <td>4</td>\n      <td>4+4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>002a4db09dad406c85505a00fb6f6144</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>003046e27c8ead3e3db155780dc5498e</td>\n      <td>karolinska</td>\n      <td>1</td>\n      <td>3+3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Noting that in the `test.csv` & `submission.csv` now have been truncated; it contains 3 `images_id` only."},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"                           image_id data_provider\n0  005700be7e06878e6605e7a5a39de1b2       radboud\n1  005c6e8877caf724c600fdce5d417d40    karolinska\n2  0104f76634ff89bfff1ef0804a95c380       radboud","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>data_provider</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>005700be7e06878e6605e7a5a39de1b2</td>\n      <td>radboud</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005c6e8877caf724c600fdce5d417d40</td>\n      <td>karolinska</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0104f76634ff89bfff1ef0804a95c380</td>\n      <td>radboud</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"                           image_id  isup_grade\n0  005700be7e06878e6605e7a5a39de1b2           0\n1  005c6e8877caf724c600fdce5d417d40           0\n2  0104f76634ff89bfff1ef0804a95c380           0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>isup_grade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>005700be7e06878e6605e7a5a39de1b2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005c6e8877caf724c600fdce5d417d40</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0104f76634ff89bfff1ef0804a95c380</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Choose what device to run**"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"If we classification based on `gleason_score`; the `classes = 6`; otherwise will be 12"},{"metadata":{"trusted":true},"cell_type":"code","source":"class config:\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    IMG_WIDTH = 256\n    IMG_HEIGHT = 256\n    TEST_BATCH_SIZE = 32\n    CLASSES = 6","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initialize internal state from hashable object with `random.seed()`"},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_torch(seed=42):\n    random.seed(seed)            ## Initialize internal state from hashable object with random.seed()\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)         ## randomstate\n    torch.manual_seed(seed)      ## generate a random_numbers\n    torch.cuda.manual_seed(seed) ## generate a random_numbers for the current GPU \n                                 ## (safe to call this function if CUDA is not available; in that case, it is silently ignored)\n    \n    torch.backends.cudnn.deterministic = True  ## checking backends.cudnn\n\nseed_torch(seed = 42)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Built-in the `ResNext` Model, \n\nDefine `classess`, including:\n\n            class SEModule(nn.Module)       \n            class Bottleneck(nn.Module)\n            class SEBottleneck(BottleNeck)\n            class SEResNetBottleneck(BottleNeck)\n            class SEResNextBottleneck(BottleNeck)\n            class SENet(nn.Module)\n            class CustomSEResNeXt(nn.Module)\n            class PandaDataset(Dataset)\n            \nDefine `functions`, including:\n\n            def initialize_pretrained_model(model, num_classes, settings)\n            def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet')\n            def se_resnext101_32x4d(num_classes=1000, pretrained='imagenet')"},{"metadata":{},"cell_type":"markdown","source":"**Quick reminder 1**\n\n`super(type, object)`: bound super object; requires isinstance(obj, type)\n\n`nn.AdaptiveAvgPool2d(outdim)`: Applies a 2D adaptive average pooling over an input signal composed of several input planes.\n      \n            The output is of size H x W, for any input size.\n            The number of output features is equal to the number of input planes.\n    \n `nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')`: Applies a `2D` convolution over an input signal composed of several input planes.\n \n `nn.RELU(inplace = False)`: Applies the rectified linear unit function element-wise\n \n $$ \\text{ReLU}(x) = (x)^+ = \\max(0, x) $$"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import OrderedDict\nimport math\n\nclass SEModule(nn.Module):\n\n    def __init__(self, channels, reduction):\n        super(SEModule, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1, padding=0)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1, padding=0)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        module_input = x\n        x = self.avg_pool(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.sigmoid(x)\n        return module_input * x","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Bottleneck(nn.Module):\n    \"\"\"\n    Base class for bottlenecks that implements `forward()` method.\n    \"\"\"\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)     ## conv_olution \n        out = self.bn1(out)     ## bottle_neck\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out = self.se_module(out) + residual\n        out = self.relu(out)\n\n        return out","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Quick reminder 2 (for the rest classes: `SEBottleneck, SEResNetBottleNeck, ..., SENet`)**. They had used these following common packs:\n\n`super, nn.Conv2d` is explained in the a few preceding lines\n\n`nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)`: Applies `Batch Normalization` over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper `Batch Normalization:` `\"Accelerating Deep Network Training by Reducing Internal Covariate Shift\"`_ .\n\n$$ y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta $$\n\n`SEModule` (look back line `In [10]`, the `__init__` function contained the `params: channel & reductions`): This is a base class for all neural network modules. \n\n`nn.AvgPool2d(kernel_size, stride = None, padding = 0, ceil_mode = False, count_include_pad = True, divisor_override = None)`: Applies a 2D average pooling over an input signal composed of several input planes.\n\n`nn.Dropout(p = 0.5, inplace = False)`: During training, randomly zeroes some of the elements of the input tensor with probability `:attr: p` using samples from a `Bernoulli` distribution. Each channel will be zeroed out independently on every forward call.\n\n`nn.Linear(in_features, out_features, bias=True)` (look down line `In [17] class CustomSEResNext`). This function applies a linear transformation to the incoming data: $y = xA^T + b$"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SEBottleneck(Bottleneck):\n    \"\"\"\n    Bottleneck for SENet154.\n    \"\"\"\n    expansion = 4\n    def __init__(self, inplanes, planes, groups, reduction, stride = 1, downsample = None):\n\n        super(SEBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes * 2)\n        \n        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size = 3,\n                               stride=stride, padding = 1, groups = groups, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes * 4)\n        \n        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n                               bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        \n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SEResNetBottleneck(Bottleneck):\n    \"\"\"\n    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n    (the latter is used in the torchvision implementation of ResNet).\n    \"\"\"\n    expansion = 4\n\n    def __init__(self, inplanes, planes, groups, reduction, stride = 1, downsample = None):\n        super(SEResNetBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size = 1, bias = False, stride = stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, padding = 1,\n                               groups = groups, bias = False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size = 1, bias = False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace = True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SEResNeXtBottleneck(Bottleneck):\n    \"\"\"\n    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n    \"\"\"\n    expansion = 4\n\n    def __init__(self, inplanes, planes, groups, reduction, stride = 1,\n                 downsample = None, base_width = 4):\n        super(SEResNeXtBottleneck, self).__init__()\n        width = math.floor(planes * (base_width / 64)) * groups\n        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False, stride=1)\n        self.bn1 = nn.BatchNorm2d(width)\n        self.conv2 = nn.Conv2d(width, width, kernel_size = 3, stride = stride,\n                               padding = 1, groups = groups, bias = False)\n        self.bn2 = nn.BatchNorm2d(width)\n        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size = 1, bias = False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace = True)\n        self.se_module = SEModule(planes * 4, reduction = reduction)\n        self.downsample = downsample\n        self.stride = stride","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SENet(nn.Module):\n    def __init__(self, block, layers, groups, reduction, dropout_p = 0.2,\n                 inplanes = 128, input_3x3 = True, downsample_kernel_size = 3,\n                 downsample_padding = 1, num_classes = 1000):\n        \n        super(SENet, self).__init__()\n        self.inplanes = inplanes\n        if input_3x3:\n            layer0_modules = [ ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1, bias=False)),\n                                ('bn1', nn.BatchNorm2d(64)),\n                                ('relu1', nn.ReLU(inplace=True)),\n                                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,bias=False)),\n                                ('bn2', nn.BatchNorm2d(64)),\n                                ('relu2', nn.ReLU(inplace=True)),\n                                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1, bias=False)),\n                                ('bn3', nn.BatchNorm2d(inplanes)),\n                                ('relu3', nn.ReLU(inplace=True)) ]\n        else:\n            layer0_modules = [ ('conv1', nn.Conv2d(3, inplanes, kernel_size = 7, stride = 2, \n                                                   padding = 3, bias = False)),\n                              ('bn1', nn.BatchNorm2d(inplanes)), \n                              ('relu1', nn.ReLU(inplace = True)) ]\n        # create the layers\n        # To preserve compatibility with Caffe weights `ceil_mode=True` is used instead of `padding=1`.\n        layer0_modules.append(('pool', nn.MaxPool2d(3, stride = 2, ceil_mode = True)))\n        \n        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n        \n        self.layer1 = self._make_layer( block, planes = 64, blocks = layers[0],\n                                        groups = groups, reduction = reduction,\n                                       downsample_kernel_size = 1, \n                                       downsample_padding = 0 )\n        \n        self.layer2 = self._make_layer( block, planes = 128, blocks=layers[1], stride=2,\n                                        groups = groups, reduction=reduction,\n                                        downsample_kernel_size = downsample_kernel_size,\n                                        downsample_padding = downsample_padding )\n\n        self.layer3 = self._make_layer( block, planes = 256, blocks = layers[2], stride=2,\n                                        groups = groups, reduction = reduction,\n                                        downsample_kernel_size = downsample_kernel_size,\n                                        downsample_padding = downsample_padding )\n        \n        self.layer4 = self._make_layer( block, planes = 512, blocks=layers[3], stride = 2,\n                                        groups = groups, reduction=reduction,\n                                        downsample_kernel_size = downsample_kernel_size,\n                                        downsample_padding = downsample_padding )\n        \n        self.avg_pool = nn.AvgPool2d(7, stride = 1)\n        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n                    downsample_kernel_size=1, downsample_padding=0):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential( nn.Conv2d( self.inplanes, planes * block.expansion,\n                                                   kernel_size = downsample_kernel_size, stride = stride,\n                                                   padding = downsample_padding, bias = False),\n                                        nn.BatchNorm2d(planes * block.expansion))\n\n        layers = []\n        layers.append(block(self.inplanes, planes, groups, reduction, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, groups, reduction))\n\n        return nn.Sequential(*layers)\n\n    def features(self, x):\n        x = self.layer0(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        return x\n\n    def logits(self, x):\n        x = self.avg_pool(x)\n        if self.dropout is not None:\n            x = self.dropout(x)\n        x = x.view(x.size(0), -1)\n        x = self.last_linear(x)\n        return x\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.logits(x)\n        return x","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def initialize_pretrained_model(model, num_classes, settings):\n    assert num_classes == settings['num_classes'], \\\n        'num_classes should be {}, but is {}'.format(settings['num_classes'], num_classes)\n    model.load_state_dict(model_zoo.load_url(settings['url']))\n    model.input_space = settings['input_space']\n    model.input_size = settings['input_size']\n    model.input_range = settings['input_range']\n    model.mean = settings['mean']\n    model.std = settings['std']\n\n\ndef se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n                  dropout_p=None, inplanes=64, input_3x3=False,\n                  downsample_kernel_size=1, downsample_padding=0,\n                  num_classes=num_classes)\n    if pretrained is not None:\n        settings = config.pretrained_settings['se_resnext50_32x4d'][pretrained]\n        initialize_pretrained_model(model, num_classes, settings)\n    return model\n\n\ndef se_resnext101_32x4d(num_classes=1000, pretrained='imagenet'):\n    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n                  dropout_p=None, inplanes=64, input_3x3=False,\n                  downsample_kernel_size=1, downsample_padding=0,\n                  num_classes=num_classes)\n    if pretrained is not None:\n        settings = config.pretrained_settings['se_resnext101_32x4d'][pretrained]\n        initialize_pretrained_model(model, num_classes, settings)\n    return model","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomSEResNeXt(nn.Module):\n\n    def __init__(self, model_name='se_resnext50_32x4d'):\n        assert model_name in ('se_resnext50_32x4d')\n        super().__init__()\n        \n        self.model = se_resnext50_32x4d(pretrained=None)\n        self.model.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.model.last_linear = nn.Linear(self.model.last_linear.in_features, config.CLASSES)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class PandaDataset(Dataset):\n    def __init__(self, images, img_height, img_width):\n        self.images = images\n        self.img_height = img_height\n        self.img_width = img_width\n        \n        # we are in validation part\n        self.aug = albumentations.Compose([\n            albumentations.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225], always_apply=True)\n        ])\n\n    def __len__(self):\n        return len(self.images)\n\n\n    def __getitem__(self, idx):\n\n        img_name = self.images[idx]\n        img_path = os.path.join(data_dir, f'{img_name}.tiff')\n\n        img = skimage.io.MultiImage(img_path)\n        img = cv2.resize(img[-1], (512, 512))\n        save_path =  f'{img_name}.png'\n        cv2.imwrite(save_path, img)\n        img = skimage.io.MultiImage(save_path)\n            \n        img = cv2.resize(img[-1], (self.img_height, self.img_width))\n\n        img = Image.fromarray(img).convert(\"RGB\")\n        img = self.aug(image=np.array(img))[\"image\"]\n        img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n\n        return { 'image': torch.tensor(img, dtype=torch.float) }","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading a model **`resnext50`**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CustomSEResNeXt(model_name='se_resnext50_32x4d')\nprint(type(model))","execution_count":19,"outputs":[{"output_type":"stream","text":"<class '__main__.CustomSEResNeXt'>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights_path = '../input/panda-resnext/resnext50_2.pth'\nmodel.load_state_dict(torch.load(weights_path, map_location=config.device))\nmodel","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"CustomSEResNeXt(\n  (model): SENet(\n    (layer0): Sequential(\n      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu1): ReLU(inplace=True)\n      (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n    )\n    (layer1): Sequential(\n      (0): SEResNeXtBottleneck(\n        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): SEResNeXtBottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (2): SEResNeXtBottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (layer2): Sequential(\n      (0): SEResNeXtBottleneck(\n        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): SEResNeXtBottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (2): SEResNeXtBottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (3): SEResNeXtBottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (layer3): Sequential(\n      (0): SEResNeXtBottleneck(\n        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): SEResNeXtBottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (2): SEResNeXtBottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (3): SEResNeXtBottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (4): SEResNeXtBottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (5): SEResNeXtBottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (layer4): Sequential(\n      (0): SEResNeXtBottleneck(\n        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): SEResNeXtBottleneck(\n        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (2): SEResNeXtBottleneck(\n        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n    (last_linear): Linear(in_features=2048, out_features=6, bias=True)\n  )\n)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Predict & evaluate**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\npredictions = []\n\ndevice = config.device\n\nif os.path.exists('../input/prostate-cancer-grade-assessment/test_images'):\n    test_dataset = PandaDataset( images = test.image_id.values,\n                                img_height = config.IMG_HEIGHT, \n                                img_width = config.IMG_WIDTH)\n\n    test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size = config.TEST_BATCH_SIZE, \n                                                   shuffle = False)\n    \n    model.to(device)\n    \n    for idx, d in tqdm(enumerate(test_data_loader), total = len(test_data_loader)):\n        inputs = d[\"image\"]\n        inputs = inputs.to(device)\n        with torch.no_grad():\n            outputs = model(inputs)\n            print(inputs, outputs)\n        predictions.append(outputs.argmax(1).cpu().detach().numpy())\n    predictions = np.concatenate(predictions)\nprint(predictions)","execution_count":21,"outputs":[{"output_type":"stream","text":"[]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Create a submission file\n\nNoting that if the `test.csv` only contains 3 image_id, then the `predictions = []` so its `len = 0`; hence we reuse the result in `isup_grade` from `submission.csv`;"},{"metadata":{"trusted":true},"cell_type":"code","source":"if len(predictions) > 0:\n    submission.isup_grade = predictions\n    submission.isup_grade = submission['isup_grade'].astype(int)\n    \nsubmission.to_csv('submission.csv',index=False)\nsubmission","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"                           image_id  isup_grade\n0  005700be7e06878e6605e7a5a39de1b2           0\n1  005c6e8877caf724c600fdce5d417d40           0\n2  0104f76634ff89bfff1ef0804a95c380           0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>isup_grade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>005700be7e06878e6605e7a5a39de1b2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005c6e8877caf724c600fdce5d417d40</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0104f76634ff89bfff1ef0804a95c380</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}